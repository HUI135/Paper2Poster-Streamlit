import streamlit as st
import arxiv
import fitz  # PyMuPDF
from openai import OpenAI
from PIL import Image, ImageDraw, ImageFont, ImageOps
import requests
from io import BytesIO
import qrcode
import json

# --- Streamlit í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="PosterGenius Assistant v5", layout="wide")

# --- í°íŠ¸ ë¡œë“œ ---
def load_font(font_filename):
    try:
        font_b = ImageFont.truetype(font_filename, 48)  # ê°€ë¡œí˜•ì— ë§ê²Œ í°íŠ¸ í¬ê¸° ì¡°ì •
        font_rl = ImageFont.truetype(font_filename.replace("Bold", "Regular"), 28)
        font_rs = ImageFont.truetype(font_filename.replace("Bold", "Regular"), 22)
        return font_b, font_rl, font_rs
    except IOError:
        st.error(f"'{font_filename}' í°íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None, None

font_bold, font_regular_large, font_regular_small = load_font("NotoSansKR-Bold.otf")

# --- í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ---

def extract_all_images_from_pdf(pdf_stream):
    images = []
    try:
        pdf_stream.seek(0)
        doc = fitz.open(stream=pdf_stream, filetype="pdf")
        for page in doc:
            for img_info in page.get_images(full=True):
                if img_info[0] < 0: continue # In-line image skip
                if img_info[2] < 100 or img_info[3] < 100: continue
                
                base_image = doc.extract_image(img_info[0])
                pil_image = Image.open(BytesIO(base_image["image"]))
                if pil_image.mode != "RGB":
                    pil_image = pil_image.convert("RGB")
                images.append(pil_image)
        return images
    except Exception as e:
        st.warning(f"ì´ë¯¸ì§€ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return []

# â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼ ê°œì„  3: GPTë¥¼ ì´ìš©í•œ ì„¹ì…˜ ì¶”ì¶œ â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼
def extract_sections_with_gpt(client, text):
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ìš” ì„¹ì…˜ì˜ ë‚´ìš©ì„ JSON í˜•íƒœë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    st.info("GPTê°€ ë…¼ë¬¸ ì „ì²´ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ ì£¼ìš” ì„¹ì…˜ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
    system_prompt = """
    You are an expert academic assistant. Your task is to extract the full text content of the "Introduction", "Methodology", and "Results" sections from the provided academic paper text.
    - For "Methodology", also look for "Methods" or "Materials and Methods".
    - For "Results", also look for "Experiments" or "Experimental Results".
    - Respond ONLY with a valid JSON object.
    - The JSON object must have three keys: "introduction", "methodology", "results".
    - The value for each key should be the complete, extracted text of that section.
    - If a section cannot be found, the value should be an empty string "".
    - Do not include any explanations or text outside of the JSON object.
    """
    try:
        response = client.chat.completions.create(
            model="gpt-4-turbo",  # êµ¬ì¡° ë¶„ì„ì—ëŠ” ë” ì„±ëŠ¥ ì¢‹ì€ ëª¨ë¸ì„ ê¶Œì¥
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": text[:15000]} # í† í° ì œí•œ ê³ ë ¤
            ],
            response_format={"type": "json_object"}
        )
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        st.error(f"GPT ê¸°ë°˜ ì„¹ì…˜ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {"introduction": "", "methodology": "", "results": "ì„¹ì…˜ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}

def summarize_text_with_gpt(client, text, section_name):
    if not text.strip(): return f"[{section_name} ì„¹ì…˜ì˜ ë‚´ìš©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.]"
    # ... (ìš”ì•½ í•¨ìˆ˜ëŠ” ì´ì „ê³¼ ë™ì¼)
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "system", "content": "You are a helpful assistant that summarizes academic papers in Korean."},
                      {"role": "user", "content": f"ë‹¤ìŒ {section_name}ì„ í•œêµ­ì–´ 3-4ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜:\n\n{text}"}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"[{section_name} ìš”ì•½ ì‹¤íŒ¨]"

# â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼ ê°œì„  1: ê°€ë¡œí˜• í¬ìŠ¤í„° ìƒì„± í•¨ìˆ˜ â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼
def create_landscape_poster(title, authors, summaries, key_image=None, arxiv_link=None):
    width, height = 1600, 900  # ê°€ë¡œí˜• í¬ê¸°
    img = Image.new('RGB', (width, height), color="#FFFFFF")
    d = ImageDraw.Draw(img)
    
    def draw_multiline_text(position, text, font, max_width, fill, spacing=10):
        x, y = position
        lines = []
        words = text.split()
        if not words: return y
        line = ""
        for word in words:
            if d.textlength(line + word + " ", font=font) <= max_width:
                line += word + " "
            else:
                lines.append(line); line = word + " "
        lines.append(line)
        for line in lines:
            d.text((x, y), line, font=font, fill=fill)
            y += font.getbbox("A")[3] + spacing
        return y

    # --- í—¤ë” (ìƒë‹¨ ì „ì²´) ---
    d.rectangle([(0, 0), (width, 120)], fill="#F0F2F6")
    if arxiv_link:
        qr_img = qrcode.make(arxiv_link).resize((90, 90))
        img.paste(qr_img, (width - 120, 15))
    draw_multiline_text((40, 30), title, font_bold, 1400, "#0E1117")
    
    # --- 2ë‹¨ ë ˆì´ì•„ì›ƒ ì„¤ì • ---
    col1_x, col2_x = 40, 840
    col_width = 720
    current_y1, current_y2 = 150, 150
    
    # --- 1ë‹¨: Introduction & Image ---
    if "introduction" in summaries:
        current_y1 = draw_multiline_text((col1_x, current_y1), "Introduction", font_regular_large, col_width, "#4A6CFA", 5)
        d.line([(col1_x, current_y1), (col1_x + col_width, current_y1)], fill="#DDDDDD", width=2)
        current_y1 += 15
        current_y1 = draw_multiline_text((col1_x, current_y1), summaries["introduction"], font_regular_small, col_width, "#31333F")
        current_y1 += 30

    if key_image:
        key_image.thumbnail((col_width, 400))
        img.paste(key_image, (col1_x, current_y1))

    # --- 2ë‹¨: Methodology & Results ---
    if "methodology" in summaries:
        current_y2 = draw_multiline_text((col2_x, current_y2), "Methodology", font_regular_large, col_width, "#4A6CFA", 5)
        d.line([(col2_x, current_y2), (col2_x + col_width, current_y2)], fill="#DDDDDD", width=2)
        current_y2 += 15
        current_y2 = draw_multiline_text((col2_x, current_y2), summaries["methodology"], font_regular_small, col_width, "#31333F")
        current_y2 += 30
        
    if "results" in summaries:
        current_y2 = draw_multiline_text((col2_x, current_y2), "Results", font_regular_large, col_width, "#4A6CFA", 5)
        d.line([(col2_x, current_y2), (col2_x + col_width, current_y2)], fill="#DDDDDD", width=2)
        current_y2 += 15
        current_y2 = draw_multiline_text((col2_x, current_y2), summaries["results"], font_regular_small, col_width, "#31333F")

    return img

# --- Streamlit App UI ---
if font_bold:
    st.title("ğŸ“„â¡ï¸ğŸ–¼ï¸ PosterGenius Assistant (v5)")
    st.markdown("AIê°€ ë…¼ë¬¸ì„ **ë¶„ì„/ìš”ì•½**í•˜ê³ , ì‚¬ìš©ìê°€ **ì´ë¯¸ì§€ë¥¼ ì„ íƒ**í•˜ë©´ **ê°€ë¡œí˜• í¬ìŠ¤í„° ì´ˆì•ˆ**ì„ ìƒì„±í•©ë‹ˆë‹¤.")

    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •"); openai_api_key = st.secrets.get("OPENAI_API_KEY")
        if not openai_api_key: st.error("API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        input_option = st.radio("1. ì…ë ¥ ë°©ì‹ ì„ íƒ:", ('arXiv ID', 'PDF íŒŒì¼ ì—…ë¡œë“œ'))

    pdf_stream, paper_info = None, None
    if input_option == 'arXiv ID':
        arxiv_id_input = st.text_input("2. ë…¼ë¬¸ arXiv ID ì…ë ¥", "1703.06868")
        if arxiv_id_input:
            paper_info = arxiv.Search(id_list=[arxiv_id_input]).results().__next__()
            if paper_info:
                pdf_stream = BytesIO(requests.get(paper_info.pdf_url).content)
                st.success(f"**{paper_info.title}** ë¡œë“œ ì™„ë£Œ!")
    else:
        uploaded_file = st.file_uploader("2. ë…¼ë¬¸ PDF ì—…ë¡œë“œ", type="pdf")
        if uploaded_file:
            paper_info = {"title": uploaded_file.name.replace(".pdf", "")}
            pdf_stream = BytesIO(uploaded_file.getvalue())

    if pdf_stream:
        st.markdown("---")
        st.subheader("3. í¬ìŠ¤í„°ì— í¬í•¨í•  ì´ë¯¸ì§€ ì„ íƒ")
        extracted_images = extract_all_images_from_pdf(pdf_stream)
        
        selected_image, image_to_use = None, None
        if extracted_images:
            cols = st.columns(len(extracted_images))
            for i, image in enumerate(extracted_images):
                with cols[i]:
                    st.image(image, caption=f"ì´ë¯¸ì§€ {i+1}", use_column_width=True)
            
            selected_option = st.selectbox("í¬ìŠ¤í„°ì— ë„£ì„ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”.", ["ì„ íƒ ì•ˆí•¨"] + [f"ì´ë¯¸ì§€ {i+1}" for i in range(len(extracted_images))])
            if selected_option != "ì„ íƒ ì•ˆí•¨":
                selected_image = extracted_images[int(selected_option.split(" ")[1]) - 1]
                # â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼ ê°œì„  2: ì´ë¯¸ì§€ ì¢Œìš° ë°˜ì „ ì˜µì…˜ â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼
                if st.checkbox("ì„ íƒí•œ ì´ë¯¸ì§€ ì¢Œìš° ë°˜ì „ (ë’¤ì§‘íŒ ê²½ìš° ì²´í¬)"):
                    image_to_use = ImageOps.mirror(selected_image)
                else:
                    image_to_use = selected_image
        else:
            st.warning("ì¶”ì¶œí•  ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        st.markdown("---")
        if st.button("ğŸš€ í¬ìŠ¤í„° ìƒì„±í•˜ê¸°!", type="primary", disabled=(not openai_api_key)):
            client = OpenAI(api_key=openai_api_key)
            pdf_stream.seek(0)
            full_text = "".join(p.get_text() for p in fitz.open(stream=pdf_stream, filetype="pdf"))
            
            extracted_sections = extract_sections_with_gpt(client, full_text)
            
            summaries = {}
            with st.spinner("ê° ì„¹ì…˜ ë‚´ìš©ì„ ìš”ì•½í•˜ëŠ” ì¤‘..."):
                for section_name, section_text in extracted_sections.items():
                    summaries[section_name] = summarize_text_with_gpt(client, section_text, section_name)
            
            with st.spinner("í¬ìŠ¤í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤..."):
                title = getattr(paper_info, 'title', paper_info.get('title', ''))
                authors = [str(a) for a in getattr(paper_info, 'authors', [])]
                arxiv_link = getattr(paper_info, 'entry_id', None)
                
                poster_image = create_landscape_poster(title, authors, summaries, image_to_use, arxiv_link)
                st.success("ğŸ‰ í¬ìŠ¤í„° ìƒì„± ì™„ë£Œ!")
                st.image(poster_image, use_column_width=True)
                
                img_byte_arr = BytesIO()
                poster_image.save(img_byte_arr, format='PNG')
                st.download_button("ğŸ“¥ í¬ìŠ¤í„° ë‹¤ìš´ë¡œë“œ", img_byte_arr.getvalue(), "poster.png", "image/png")