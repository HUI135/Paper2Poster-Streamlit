import streamlit as st
import arxiv
import fitz  # PyMuPDF
from openai import OpenAI
from PIL import Image, ImageDraw, ImageFont, ImageOps
import requests
from io import BytesIO
import qrcode
import json

# --- Streamlit í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="PosterGenius Assistant v8", layout="wide")

# --- í°íŠ¸ ë¡œë“œ ---
def load_font(font_filename):
    try:
        font_b = ImageFont.truetype(font_filename, 48)
        font_rl = ImageFont.truetype(font_filename.replace("Bold", "Regular"), 28)
        font_rs = ImageFont.truetype(font_filename.replace("Bold", "Regular"), 20)
        font_caption = ImageFont.truetype(font_filename.replace("Bold", "Regular"), 16)
        return font_b, font_rl, font_rs, font_caption
    except IOError:
        st.error(f"'{font_filename}' í°íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return (None,)*4

font_bold, font_regular_large, font_regular_small, font_caption = load_font("NotoSansKR-Bold.otf")


# --- í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ---

def extract_images_from_pdf(pdf_stream):
    images = []
    try:
        pdf_stream.seek(0)
        doc = fitz.open(stream=pdf_stream, filetype="pdf")
        for page in doc:
            for img_info in page.get_images(full=True):
                if img_info[0] < 0 or img_info[2] < 150 or img_info[3] < 150: continue
                base_image = doc.extract_image(img_info[0])
                pil_image = Image.open(BytesIO(base_image["image"]))
                if pil_image.mode != "RGB": pil_image = pil_image.convert("RGB")
                images.append(pil_image)
        return images
    except Exception as e:
        st.warning(f"ì´ë¯¸ì§€ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}"); return []

def extract_and_summarize(client, text):
    st.info("GPTê°€ ë…¼ë¬¸ ì „ì²´ë¥¼ ë¶„ì„í•˜ì—¬ ì„¹ì…˜ ì¶”ì¶œ ë° ìš”ì•½ì„ ë™ì‹œì— ì§„í–‰í•©ë‹ˆë‹¤...")
    system_prompt = "You are an expert academic assistant. Your task is to analyze an academic paper's text. First, extract the content of the 'Introduction', 'Methodology', and 'Results' sections. For 'Methodology', also accept 'Methods'. For 'Results', also accept 'Experiments'. Then, summarize each extracted section in 3-4 sentences in KOREAN. Respond ONLY with a valid JSON object. The JSON object must have keys 'introduction_summary', 'methodology_summary', and 'results_summary'. If a section is not found, its summary should be a string stating that. Do not include explanations outside the JSON."
    try:
        response = client.chat.completions.create(model="gpt-4-turbo", messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": text[:15000]}], response_format={"type": "json_object"})
        summaries = json.loads(response.choices[0].message.content)
        return summaries
    except Exception as e:
        st.error(f"GPT ê¸°ë°˜ ì¶”ì¶œ/ìš”ì•½ ì¤‘ ì˜¤ë¥˜: {e}"); return {k: "ì²˜ë¦¬ ì‹¤íŒ¨" for k in ["introduction_summary", "methodology_summary", "results_summary"]}

# â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼ ê°œì„ : 3ë‹¨ ë ˆì´ì•„ì›ƒ í¬ìŠ¤í„° ìƒì„± í•¨ìˆ˜ ë³µì› â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼
def create_3_column_poster(title, authors, summaries, images=[], arxiv_link=None):
    width, height = 1800, 1000
    img = Image.new('RGB', (width, height), color="#FFFFFF")
    d = ImageDraw.Draw(img)
    
    def draw_multiline_text(position, text, font, max_width, fill, spacing=10):
        x, y = position; lines = []; words = text.split()
        if not words: return y
        line = ""
        for word in words:
            if d.textlength(line + word + " ", font=font) <= max_width: line += word + " "
            else: lines.append(line); line = word + " "
        lines.append(line)
        for line in lines: d.text((x, y), line, font=font, fill=fill); y += font.getbbox("A")[3] + spacing
        return y

    d.rectangle([(0, 0), (width, 120)], fill="#F0F2F6")
    if arxiv_link:
        qr_img = qrcode.make(arxiv_link).resize((90, 90)); img.paste(qr_img, (width - 120, 15))
    draw_multiline_text((40, 30), title, font_bold, 1600, "#0E1117")
    
    margin, gap = 40, 40
    col_width = (width - 2 * margin - 2 * gap) // 3
    col1_x, col2_x, col3_x = margin, margin + col_width + gap, margin + 2 * (col_width + gap)
    current_y = [150] * 3

    def draw_section(col_index, title, content):
        col_x = [col1_x, col2_x, col3_x][col_index]
        y = current_y[col_index]
        y = draw_multiline_text((col_x, y), title, font_regular_large, col_width, "#4A6CFA", 5)
        d.line([(col_x, y), (col_x + col_width, y)], fill="#DDDDDD", width=2)
        y += 15
        y = draw_multiline_text((col_x, y), content, font_regular_small, col_width, "#31333F")
        current_y[col_index] = y + 30

    if "introduction_summary" in summaries: draw_section(0, "Introduction", summaries["introduction_summary"])
    if "methodology_summary" in summaries: draw_section(0, "Methodology", summaries["methodology_summary"])
    if "results_summary" in summaries: draw_section(1, "Results", summaries["results_summary"])

    if images:
        y = current_y[2]
        y = draw_multiline_text((col3_x, y), "Figures & Tables", font_regular_large, col_width, "#4A6CFA", 5)
        d.line([(col3_x, y), (col3_x + col_width, y)], fill="#DDDDDD", width=2)
        y += 15
        for i, key_image in enumerate(images):
            key_image.thumbnail((col_width, col_width))
            img.paste(key_image, (col3_x, y))
            y += key_image.height + 5
            draw_multiline_text((col3_x, y), f"[Fig. {i+1}]", font_caption, col_width, "#888888")
            y += 25
        current_y[2] = y
    return img

# --- Streamlit App UI ---
if font_bold:
    st.title("ğŸ“„â¡ï¸ğŸ–¼ï¸ PosterGenius Assistant (v8)")
    st.markdown("AIê°€ ë…¼ë¬¸ì„ ë¶„ì„/ìš”ì•½í•˜ê³ , ì‚¬ìš©ìê°€ **ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ì„ íƒ**í•˜ë©´ **3ë‹¨ ê°€ë¡œí˜• í¬ìŠ¤í„°**ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •"); openai_api_key = st.secrets.get("OPENAI_API_KEY")
        if not openai_api_key: st.error("API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        input_option = st.radio("1. ì…ë ¥ ë°©ì‹ ì„ íƒ:", ('arXiv ID', 'PDF íŒŒì¼ ì—…ë¡œë“œ'))

    pdf_stream, paper_info = None, None
    if input_option == 'arXiv ID':
        arxiv_id_input = st.text_input("2. ë…¼ë¬¸ arXiv ID ì…ë ¥", "2005.12872")
        if arxiv_id_input:
            try:
                paper_info = arxiv.Search(id_list=[arxiv_id_input]).results().__next__()
                if paper_info:
                    with st.spinner('ë…¼ë¬¸ PDF ë‹¤ìš´ë¡œë“œ ì¤‘...'): pdf_stream = BytesIO(requests.get(paper_info.pdf_url).content)
                    st.success(f"**{paper_info.title}** ë¡œë“œ ì™„ë£Œ!")
            except StopIteration: st.error("í•´ë‹¹ IDì˜ ë…¼ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        uploaded_file = st.file_uploader("2. ë…¼ë¬¸ PDF ì—…ë¡œë“œ", type="pdf")
        if uploaded_file:
            paper_info = {"title": uploaded_file.name.replace(".pdf", "")}; pdf_stream = BytesIO(uploaded_file.getvalue())

    # --- ì´ë¯¸ì§€ ì„ íƒ ë¡œì§ ì´ˆê¸°í™” ---
    if 'selected_images' not in st.session_state:
        st.session_state.selected_images = []

    if pdf_stream:
        st.markdown("---")
        st.subheader("3. í¬ìŠ¤í„°ì— í¬í•¨í•  ì´ë¯¸ì§€ ì„ íƒ")
        extracted_images = extract_images_from_pdf(pdf_stream)
        
        if extracted_images:
            # â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼ ê°œì„ : ìƒˆë¡œìš´ ì´ë¯¸ì§€ ì„ íƒ UI â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼
            st.info("í¬ìŠ¤í„°ì— í¬í•¨í•  ì˜¬ë°”ë¥¸ ë°©í–¥ì˜ ì´ë¯¸ì§€ë¥¼ í´ë¦­í•˜ì—¬ ì„ íƒí•˜ì„¸ìš”. ë‹¤ì¤‘ ì„ íƒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            
            # ì„ íƒëœ ì´ë¯¸ì§€ë¥¼ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ë¡œì§
            if 'chosen_indices' not in st.session_state: st.session_state.chosen_indices = []
            
            num_images = len(extracted_images)
            cols = st.columns(num_images) # ìš”ì²­ëŒ€ë¡œ ê°€ë¡œë¡œ ë‚˜ì—´
            
            for i, image in enumerate(extracted_images):
                with cols[i]:
                    st.write(f"**ì´ë¯¸ì§€ {i+1}**")
                    col1, col2 = st.columns(2)
                    with col1:
                        st.image(image, caption="ì›ë³¸", use_container_width=True)
                        if st.button(f"ì´ ì´ë¯¸ì§€ ì„ íƒ##{i}_orig", use_container_width=True):
                            if (i, "orig") not in st.session_state.chosen_indices:
                                st.session_state.chosen_indices.append((i, "orig"))
                            else:
                                st.session_state.chosen_indices.remove((i, "orig"))
                    with col2:
                        flipped_image = ImageOps.mirror(image)
                        st.image(flipped_image, caption="ì¢Œìš°ë°˜ì „", use_container_width=True)
                        if st.button(f"ì´ ì´ë¯¸ì§€ ì„ íƒ##{i}_flip", use_container_width=True):
                            if (i, "flip") not in st.session_state.chosen_indices:
                                st.session_state.chosen_indices.append((i, "flip"))
                            else:
                                st.session_state.chosen_indices.remove((i, "flip"))
            
            st.markdown("---")
            st.write("**í˜„ì¬ ì„ íƒëœ ì´ë¯¸ì§€:**")
            images_to_use = []
            for idx, orientation in st.session_state.chosen_indices:
                img_to_add = extracted_images[idx]
                if orientation == "flip":
                    img_to_add = ImageOps.mirror(img_to_add)
                images_to_use.append(img_to_add)
            
            if images_to_use:
                st.image(images_to_use, width=150)
            else:
                st.write("ì„ íƒëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            # â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²

        else:
            st.warning("ì¶”ì¶œí•  ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."); images_to_use = []

        st.markdown("---")
        if st.button("ğŸš€ í¬ìŠ¤í„° ìƒì„±í•˜ê¸°!", type="primary", disabled=(not openai_api_key)):
            client = OpenAI(api_key=openai_api_key)
            pdf_stream.seek(0)
            full_text = "".join(p.get_text() for p in fitz.open(stream=pdf_stream, filetype="pdf"))
            
            summaries = extract_and_summarize(client, full_text)
            
            with st.spinner("í¬ìŠ¤í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤..."):
                title = getattr(paper_info, 'title', paper_info.get('title', ''))
                authors = [str(a) for a in getattr(paper_info, 'authors', [])]
                arxiv_link = getattr(paper_info, 'entry_id', None)
                
                poster_image = create_3_column_poster(title, authors, summaries, images_to_use, arxiv_link)
                st.success("ğŸ‰ í¬ìŠ¤í„° ìƒì„± ì™„ë£Œ!")
                st.image(poster_image, use_container_width=True)
                
                img_byte_arr = BytesIO(); poster_image.save(img_byte_arr, format='PNG')
                st.download_button("ğŸ“¥ í¬ìŠ¤í„° ë‹¤ìš´ë¡œë“œ", img_byte_arr.getvalue(), "poster.png", "image/png")
